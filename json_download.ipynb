{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5e37d4",
   "metadata": {},
   "source": [
    "### Download Data from Cloud\n",
    "This notebook will also convert files from JSON to csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8df67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91371dcb",
   "metadata": {},
   "source": [
    "Initialise AWS session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6254d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set credentials\n",
    "session = boto3.Session( \n",
    "         aws_access_key_id='AKIAWBTUBJCDLIOY2ATO', \n",
    "         aws_secret_access_key='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')\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "bucket = 'clear-coles-uts'\n",
    "s3_bucket = s3.Bucket(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4cb07",
   "metadata": {},
   "source": [
    "Add functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dce961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_file_list(bucket):\n",
    "    \"\"\"\n",
    "        File list from Coles' s3 \n",
    "    \"\"\"\n",
    "    sub_dir = bucket.objects.filter(Prefix=\"analytics-fy22/\")\n",
    "    \n",
    "    files = [obj.key for obj in sub_dir if obj.key.endswith('.json')]\n",
    "    \n",
    "    return files\n",
    "\n",
    "\n",
    "def s3_file_load(bucket, file):\n",
    "    \"\"\"\n",
    "        Download individual json files and convert\n",
    "    \"\"\"\n",
    "    obj = s3.Object(bucket, file)\n",
    "    content = obj.get()['Body'].read().decode()\n",
    "        \n",
    "    data = [json.loads(line) for line in content.split('\\n')]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def download_json(bucket, file):\n",
    "    data = s3_file_load(bucket, file)\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e2037",
   "metadata": {},
   "source": [
    "Change directory for your local machine (assumes a \"data\" subfolder in the same directory as notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ecd9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = get_json_file_list(s3_bucket)\n",
    "# file_list = file_list[:5] # remove line to do full list\n",
    "save_dir = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc4901",
   "metadata": {},
   "source": [
    "Download data. Full file list (365 files) requires approx. 45-60 mins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f05e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30 time(s):\n",
      "425.53026180000006\n",
      "Batch 60 time(s):\n",
      "422.91247640000006\n",
      "Batch 90 time(s):\n",
      "527.7779241000001\n",
      "Batch 120 time(s):\n",
      "491.0317825000002\n",
      "Batch 150 time(s):\n",
      "290.55864569999994\n",
      "Batch 180 time(s):\n",
      "156.9698045\n",
      "Batch 210 time(s):\n",
      "128.88952879999988\n",
      "Batch 240 time(s):\n",
      "275.1212035999997\n",
      "Batch 270 time(s):\n",
      "236.6212227000001\n",
      "Batch 300 time(s):\n",
      "175.5086397\n",
      "Batch 330 time(s):\n",
      "236.2949878999998\n",
      "Batch 360 time(s):\n",
      "254.6684624999998\n",
      "Total time(s):\n",
      "3675.9511435000004\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "\n",
    "for i, file in enumerate(file_list):\n",
    "    \n",
    "    if i == 0:\n",
    "        t1 = time.perf_counter()\n",
    "    elif i % 30 == 0:\n",
    "        t2 = time.perf_counter()\n",
    "        print(\"Batch {} time(s):\".format(i))\n",
    "        print(t2 - t1)\n",
    "        t1 = time.perf_counter()\n",
    "        \n",
    "    data = s3_file_load(bucket, file)\n",
    "    save_name = file.replace('analytics-fy22/', './data/').replace('.json', '.csv')\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(save_name, index=False)\n",
    "    \n",
    "    #with open('./data/{}'.format(save_name), 'w') as f:\n",
    "    #    json.dump(data, f)\n",
    "    \n",
    "t3 = time.perf_counter()\n",
    "print(\"Total time(s):\")\n",
    "print(t3-t0)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073068d",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
